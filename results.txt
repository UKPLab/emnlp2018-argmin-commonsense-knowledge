Ivan's model
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5563063063063063, 0.536036036036036, 0.49774774774774777, 0.47072072072072074, 0.5315315315315315, 0.545045045045045, 0.5698198198198198, 0.46621621621621623, 0.5135135135135135, 0.5563063063063063] -> 0.5243243243243244

Ivan's model - concatenated warrants
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5427927927927928, 0.5337837837837838, 0.536036036036036, 0.5135135135135135, 0.49324324324324326, 0.49099099099099097, 0.5225225225225225, 0.5247747747747747, 0.5180180180180181, 0.5067567567567568] -> 0.5182432432432432

Ivan's model - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.5427927927927928, 0.5698198198198198, 0.581081081081081, 0.5292792792792793, 0.5157657657657657, 0.527027027027027, 0.5720720720720721, 0.5585585585585585, 0.5630630630630631, 0.5382882882882883] -> 0.5497747747747747

Ivan's model - emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5743243243243243, 0.5630630630630631, 0.5225225225225225, 0.5698198198198198, 0.5518018018018018, 0.5563063063063063, 0.5518018018018018, 0.5472972972972973, 0.5135135135135135, 0.5630630630630631] -> 0.5513513513513513

Pooled with Wikidata
Training: LSTM 64, Warrant LSTM 64, Dropout 0.35, Batch 16
Acc test: [0.5202702702702703, 0.49324324324324326, 0.5405405405405406, 0.509009009009009, 0.4774774774774775, 0.5180180180180181, 0.536036036036036, 0.5225225225225225, 0.5608108108108109, 0.527027027027027] -> 0.5204954954954956

Pooled with Wikidata
Training: LSTM 64, Warrant LSTM 256, Dropout 0.4, Batch 16
Acc dev: [0.5135135135135135, 0.4797297297297297, 0.527027027027027, 0.536036036036036, 0.5225225225225225, 0.5247747747747747, 0.5247747747747747, 0.5180180180180181, 0.5112612612612613, 0.5247747747747747] -> 0.5182432432432431

Pooled with Wikidata - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5698198198198198, 0.545045045045045, 0.5585585585585585, 0.5675675675675675, 0.5427927927927928, 0.545045045045045, 0.5540540540540541, 0.5585585585585585, 0.5608108108108109, 0.5292792792792793] -> 0.553153153153153

Pooled with FrameNet(TransE)
Training: LSTM 64, Warrant LSTM 64, Dropout 0.4, Batch 16
Acc test: [0.49324324324324326, 0.5067567567567568, 0.5202702702702703, 0.5427927927927928, 0.5022522522522522, 0.5495495495495496, 0.5382882882882883, 0.5315315315315315, 0.49774774774774777, 0.4864864864864865] -> 0.5168918918918919

Pooled with FrameNet(TransE) - concatenated warrants
Training: LSTM 64, Warrant LSTM 64, Dropout 0.4, Batch 16
Acc test: [0.5135135135135135, 0.4954954954954955, 0.5247747747747747, 0.5563063063063063, 0.5630630630630631, 0.527027027027027, 0.5315315315315315, 0.5698198198198198, 0.5315315315315315, 0.48423423423423423] -> 0.5297297297297298

Pooled with FrameNet(W2V) - concatenated warrants
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5540540540540541, 0.5225225225225225, 0.5112612612612613, 0.509009009009009, 0.5202702702702703, 0.5495495495495496, 0.5112612612612613, 0.5585585585585585, 0.5540540540540541, 0.5157657657657657] -> 0.5306306306306305

Pooled with FrameNet(TransE) - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
[0.5563063063063063, 0.5157657657657657, 0.545045045045045, 0.5405405405405406, 0.5788288288288288, 0.5743243243243243, 0.509009009009009, 0.5540540540540541, 0.5495495495495496, 0.5608108108108109] -> 0.5484234234234234

Pooled with Wikidata+FrameNet(TransE) - concatenated warrants, emb updates ????
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
[0.545045045045045, 0.5743243243243243, 0.5157657657657657, 0.536036036036036, 0.48423423423423423, 0.5923423423423423, 0.5653153153153153, 0.6013513513513513, 0.5382882882882883, 0.6126126126126126] -> 0.5565315315315315

Tokens with FrameNet(TransE) - fixed emb
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5135135135135135, 0.509009009009009, 0.5518018018018018, 0.5247747747747747] -> 0.52477477477477474

Tokens with FrameNet(TransE) - emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5720720720720721, 0.5495495495495496, 0.5495495495495496, 0.545045045045045, 0.5855855855855856, 0.545045045045045, 0.545045045045045, 0.5337837837837838, 0.5540540540540541, 0.5765765765765766] -> 0.5556306306306308

Tokens with FrameNet(TransE) - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5630630630630631, 0.5563063063063063, 0.5788288288288288, 0.5472972972972973, 0.5247747747747747, 0.5765765765765766, 0.5540540540540541, 0.5878378378378378, 0.5563063063063063, 0.5675675675675675] -> 0.5612612612612613

Tokens with FrameNet(TransE) - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 64, Dropout 0.4, Batch 16
Acc test: [0.5563063063063063, 0.5878378378378378, 0.5427927927927928, 0.5315315315315315, 0.5923423423423423, 0.5653153153153153, 0.5743243243243243, 0.5180180180180181, 0.545045045045045, 0.5630630630630631] -> 0.5576576576576576

Tokens with FrameNet(W2V) - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.6148648648648649, 0.5180180180180181, 0.5833333333333334, 0.5180180180180181, 0.5698198198198198, 0.5540540540540541, 0.5608108108108109, 0.4774774774774775, 0.5608108108108109, 0.5563063063063063] -> 0.5513513513513514


Tokens with Wikidata - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 64, Dropout 0.4, Batch 16
Acc test: [0.5472972972972973, 0.5878378378378378, 0.5923423423423423, 0.5585585585585585, 0.5765765765765766, 0.5495495495495496, 0.5157657657657657, 0.5472972972972973, 0.581081081081081, 0.536036036036036] -> 0.5592342342342341

Tokens with Wikidata - concatenated warrants, emb updates - model_kb_2018-05-18_567909
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5292792792792793, 0.5675675675675675, 0.5698198198198198, 0.5945945945945946, 0.5945945945945946, 0.5495495495495496, 0.5157657657657657, 0.5427927927927928, 0.5472972972972973, 0.5405405405405406] -> 0.5551801801801802


Tokens with Wikidata+FrameNet(TransE) - concatenated warrants, emb updates - model_kb_fn_2018-05-18_757232
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.6373873873873874, 0.5405405405405406, 0.5518018018018018, 0.5495495495495496, 0.5788288288288288, 0.5698198198198198, 0.5247747747747747, 0.5472972972972973, 0.5608108108108109, 0.5225225225225225] -> 0.5583333333333333

Tokens with Wikidata+FrameNet(W2V) - concatenated warrants, emb updates
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc test: [0.5518018018018018, 0.5743243243243243, 0.481981981981982, 0.5675675675675675, 0.481981981981982, 0.5653153153153153, 0.5765765765765766, 0.509009009009009, 0.5585585585585585, 0.5157657657657657] -> 0.5382882882882882


====================================

Ivan's model - concatenated warrants, emb updates - ih_2018-05-18_240435
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.6740506329113924, 0.6392405063291139, 0.6708860759493671, 0.680379746835443, 0.6930379746835443, 0.680379746835443, 0.6677215189873418, 0.6613924050632911, 0.6550632911392406, 0.689873417721519] -> 0.6712025316455696
Acc test: [0.536036036036036, 0.5315315315315315, 0.574324324343243, 0.5382882882882883, 0.5563063063063063, 0.5720720720720721, 0.5630630630630631, 0.5878378378378378, 0.5405405405405406, 0.5698198198198198] -> 0.556981981981982

Tokens with FrameNet(TransE) - concatenated warrants, emb updates - fn_2018-05-18_871870
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.6708860759493671, 0.6613924050632911, 0.6708860759493671, 0.6867088607594937, 0.6930379746835443, 0.6645569620253164, 0.6550632911392406, 0.689873417721519, 0.6708860759493671, 0.6772151898734177] -> 0.6740506329113924
Acc test: [0.5698198198198198, 0.5608108108108109, 0.545045045045045, 0.5315315315315315, 0.5427927927927928, 0.5968468468468469, 0.545045045045045, 0.5765765765765766, 0.6103603603603603, 0.5968468468468469] -> 0.5675675675675677

Tokens with FrameNet(W2V) - concatenated warrants, emb updates - fn_2018-05-18_378494
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.6740506329113924, 0.680379746835443, 0.6582278481012658, 0.6677215189873418, 0.6613924050632911, 0.6518987341772152, 0.6518987341772152, 0.6740506329113924, 0.6740506329113924, 0.6867088607594937] -> 0.6680379746835442
Acc test: [0.5382882882882883, 0.5743243243243243, 0.527027027027027, 0.5202702702702703, 0.5472972972972973, 0.5833333333333334, 0.5833333333333334, 0.5472972972972973, 0.5923423423423423, 0.5608108108108109] -> 0.5574324324324323

Tokens with Wikidata - concatenated warrants, emb updates - kb_2018-05-18_247704
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.6677215189873418, 0.6582278481012658, 0.6550632911392406, 0.6613924050632911, 0.6677215189873418, 0.6677215189873418, 0.6550632911392406, 0.6772151898734177, 0.6582278481012658, 0.6550632911392406] -> 0.6623417721518987
Acc test: [0.6036036036036037, 0.5945945945945946, 0.5675675675675675, 0.5382882882882883, 0.5540540540540541, 0.5923423423423423, 0.5675675675675675, 0.5382882882882883, 0.5405405405405406, 0.5833333333333334] -> 0.568018018018018

Tokens with Wikidata+FrameNet(TransE) - concatenated warrants, emb updates - kb_fn_2018-05-18_396229
Training: LSTM 32, Warrant LSTM 32, Dropout 0.25, Batch 16
Acc dev: [0.6550632911392406, 0.6645569620253164, 0.680379746835443, 0.6550632911392406, 0.6550632911392406, 0.6708860759493671, 0.6613924050632911, 0.6740506329113924, 0.6550632911392406, 0.6582278481012658] -> 0.6629746835443038
Acc test: [0.5720720720720721, 0.5563063063063063, 0.5563063063063063, 0.5720720720720721, 0.5427927927927928, 0.5608108108108109, 0.536036036036036, 0.5945945945945946, 0.5427927927927928, 0.5585585585585585] -> 0.5592342342342342
