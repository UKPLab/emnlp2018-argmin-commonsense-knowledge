import numpy as np

from semanticparsing.basemodel import models
from semanticparsing.basemodel.attention_lstm import AttentionLSTM, AttentionLSTMCell
import keras


def test_model():

    model = models.get_attention_lstm_intra_warrant_kb_pooled({"0": np.zeros(25) for i in range(400)}, 100, rich_context=True,
                                                       dropout=0.4, lstm_size=64,
                                                       warrant_lstm_size=64,
                                                       kb_embeddings=np.zeros((25, 100)),
                                                       fn_embeddings=np.zeros((25, 100))
                                                       )
    print(model.to_yaml())
    model.save("temp.model")
    keras.models.load_model("temp.model", custom_objects={
        "AttentionLSTM": AttentionLSTM,
        "AttentionLSTMCell": AttentionLSTMCell})


if __name__ == '__main__':
    test_model()
